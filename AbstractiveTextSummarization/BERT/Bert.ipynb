{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T20:32:29.193575Z","iopub.status.busy":"2024-04-11T20:32:29.192892Z","iopub.status.idle":"2024-04-11T20:32:37.754620Z","shell.execute_reply":"2024-04-11T20:32:37.753509Z","shell.execute_reply.started":"2024-04-11T20:32:29.193538Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rouge_score in /opt/conda/lib/python3.7/site-packages (0.1.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.19.5)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge_score) (0.15.0)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from rouge_score) (3.2.4)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"source":["!pip install rouge_score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T20:32:37.757248Z","iopub.status.busy":"2024-04-11T20:32:37.756901Z","iopub.status.idle":"2024-04-11T20:32:37.765741Z","shell.execute_reply":"2024-04-11T20:32:37.764959Z","shell.execute_reply.started":"2024-04-11T20:32:37.757188Z"},"trusted":true},"outputs":[],"source":["import pandas as pd \n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import transformers\n","from transformers import BertTokenizerFast, RobertaTokenizerFast, TFEncoderDecoderModel, AdamWeightDecay\n","from sklearn.model_selection import train_test_split\n","import datasets\n","from tqdm.notebook import tqdm\n","from tensorflow.python.ops.numpy_ops import np_config\n","from pprint import pprint\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preparation"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T20:32:37.767024Z","iopub.status.busy":"2024-04-11T20:32:37.766795Z","iopub.status.idle":"2024-04-11T20:32:49.317368Z","shell.execute_reply":"2024-04-11T20:32:49.316602Z","shell.execute_reply.started":"2024-04-11T20:32:37.766990Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3240044</th>\n","      <td>a dozen of cambodian journalists and governmen...</td>\n","      <td>cambodia marks world press freedom day</td>\n","    </tr>\n","    <tr>\n","      <th>2374379</th>\n","      <td>with almost ###,### hurricane katrina evacuees...</td>\n","      <td>effort to house katrina evacuees fraught with ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                      Text  \\\n","3240044  a dozen of cambodian journalists and governmen...   \n","2374379  with almost ###,### hurricane katrina evacuees...   \n","\n","                                                   Summary  \n","3240044             cambodia marks world press freedom day  \n","2374379  effort to house katrina evacuees fraught with ...  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df_reviews = pd.read_csv('gigaword_dataset.csv')\n","# df_reviews\n","df_reviews.rename(columns = {'document':'Text',\n","                        'summary':'Summary'  }, inplace = True) \n","df_reviews.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["Drop the duplicated reviews and reviews without summaries"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T20:32:49.318837Z","iopub.status.busy":"2024-04-11T20:32:49.318572Z","iopub.status.idle":"2024-04-11T20:32:49.346772Z","shell.execute_reply":"2024-04-11T20:32:49.346027Z","shell.execute_reply.started":"2024-04-11T20:32:49.318797Z"},"trusted":true},"outputs":[],"source":["df_reviews.drop_duplicates(subset=['Text'], inplace=True)\n","# print(df_reviews[df_reviews['Summary'].isnull() == True]['Text'].unique())\n","df_reviews.dropna(subset=['Summary'], inplace=True)\n","df_reviews.reset_index(inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Training Preparation"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T20:32:49.365101Z","iopub.status.busy":"2024-04-11T20:32:49.364837Z","iopub.status.idle":"2024-04-11T20:32:49.375462Z","shell.execute_reply":"2024-04-11T20:32:49.374705Z","shell.execute_reply.started":"2024-04-11T20:32:49.365067Z"},"trusted":true},"outputs":[],"source":["# Configure the training parameters\n","class TrainingConfig:\n","    val_split = 0.2\n","    pretrained_checkpoint = 'bert-base-uncased'\n","    encoder_checkpoint = 'bert-base-uncased'\n","    decoder_checkpoint = 'bert-base-uncased'\n","    pad_token_id = 0\n","    shared_weight = False\n","    encoder_max_len = 256 \n","    decoder_max_len = 30 \n","    nb_epoch = 3 \n","    learning_rate = 3e-5 \n","    batch_size = 8 \n","    \n","    def __init__(self, **kwargs):\n","        for k,v in kwargs.items():\n","            setattr(self, k, v)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T20:32:49.376768Z","iopub.status.busy":"2024-04-11T20:32:49.376558Z","iopub.status.idle":"2024-04-11T20:32:49.401952Z","shell.execute_reply":"2024-04-11T20:32:49.401150Z","shell.execute_reply.started":"2024-04-11T20:32:49.376742Z"},"trusted":true},"outputs":[],"source":["# load the train and validation dataset\n","class DataLoader:\n","    def __init__(self, paragraphs, summaries, **kwargs):\n","        self.paragraphs = paragraphs \n","        self.summaries = summaries \n","        self.tokenizer = kwargs.get('tokenizer')\n","        self.val_split = kwargs.get('val_split')\n","        self.encoder_max_len = kwargs.get('encoder_max_len')\n","        self.decoder_max_len = kwargs.get('decoder_max_len')\n","    \n","    @property\n","    def sample_size(self):\n","        assert len(self.paragraphs)==len(self.summaries)\n","        return len(self.paragraphs)\n","    \n","    def split_train_test(self):\n","        train_idx, val_idx = train_test_split(\n","            list(range(self.sample_size)), \n","            test_size=self.val_split, \n","            random_state=98\n","        )\n","        return train_idx, val_idx\n","    \n","    def convert_text_to_ids(self, input_paragraphs, input_summaries):\n","        inputs = self.tokenizer(\n","            list(input_paragraphs), \n","            return_tensors='np', \n","            padding='max_length', \n","            truncation=True, \n","            max_length=self.encoder_max_len\n","        )\n","        outputs = self.tokenizer(\n","            list(input_summaries), \n","            return_tensors='np', \n","            padding='max_length', \n","            truncation=True, \n","            max_length=self.decoder_max_len\n","        )\n","        return inputs, outputs\n","    \n","    def list_to_tensor_dataset(self, input_paragraphs, input_summaries):\n","        inputs, outputs = self.convert_text_to_ids(\n","            input_paragraphs, \n","            input_summaries\n","        )\n","        input_ids = tf.data.Dataset.from_tensor_slices(\n","            inputs['input_ids']\n","        )\n","        attention_masks = tf.data.Dataset.from_tensor_slices(\n","            inputs['attention_mask']\n","        )\n","        output_ids = tf.data.Dataset.from_tensor_slices(\n","            outputs['input_ids']\n","        )\n","        output_attention_masks = tf.data.Dataset.from_tensor_slices(\n","            outputs['attention_mask']\n","        )                                                \n","        tf_dataset = tf.data.Dataset.zip(\n","            ({\n","                'input_ids': input_ids, \n","                'attention_mask': attention_masks,\n","                'decoder_input_ids': output_ids, \n","                'decoder_attention_mask': output_attention_masks\n","            }, \n","            output_ids)\n","        )\n","        return tf_dataset\n","    \n","    def __call__(self):\n","        train_idx, val_idx = self.split_train_test()\n","        train_paras, val_paras = self.paragraphs[train_idx], self.paragraphs[val_idx]\n","        train_sums, val_sums = self.summaries[train_idx], self.summaries[val_idx]\n","        train_dataset = self.list_to_tensor_dataset(train_paras, train_sums)\n","        val_dataset = self.list_to_tensor_dataset(val_paras, val_sums)\n","        return train_dataset, val_dataset"]},{"cell_type":"markdown","metadata":{},"source":["# Model Setup"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T20:32:49.403404Z","iopub.status.busy":"2024-04-11T20:32:49.403109Z","iopub.status.idle":"2024-04-11T20:32:49.415297Z","shell.execute_reply":"2024-04-11T20:32:49.414561Z","shell.execute_reply.started":"2024-04-11T20:32:49.403365Z"},"trusted":true},"outputs":[],"source":["# Customized loss function for seq2seq model\n","class Seq2SeqLoss(tf.keras.losses.Loss):\n","    def __init__(self, pad_token_id, name=\"seq2seq_loss\"):\n","        super().__init__(name=name)\n","        self.pad_token_id = pad_token_id\n","\n","    def call(self, y_true, y_pred):\n","        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n","            from_logits=True, \n","            reduction=tf.keras.losses.Reduction.NONE\n","        )\n","        # shift the label and output sequences to match  \n","        output_logits = y_pred[:,:-1,:]\n","        input_labels = y_true[:,1:] \n","        loss = loss_fn(input_labels, output_logits)\n","        # calculate loss without the padding tokens in label sequence\n","        mask = tf.cast((input_labels != self.pad_token_id), dtype=tf.float32)\n","        loss = loss * mask\n","        return tf.reduce_sum(loss) / tf.reduce_sum(mask)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T20:32:49.416716Z","iopub.status.busy":"2024-04-11T20:32:49.416518Z","iopub.status.idle":"2024-04-11T20:32:49.428058Z","shell.execute_reply":"2024-04-11T20:32:49.427276Z","shell.execute_reply.started":"2024-04-11T20:32:49.416691Z"},"trusted":true},"outputs":[],"source":["class Trainer:\n","    def __init__(self, model, loss_fn, optimizer, metric):\n","        self.model = model\n","        self.loss_fn = loss_fn\n","        self.optimizer = optimizer\n","        self.metric = metric\n","        # loss tracker will capture the mean of loss till now\n","        self.loss_tracker = tf.keras.metrics.Mean(name='mean_loss')\n","    \n","    # Training Step\n","    @tf.function \n","    def train_step(self, inputs):\n","        input_seqs, input_labels = inputs\n","        with tf.GradientTape() as tape: \n","            outputs = self.model(\n","                input_seqs['input_ids'],\n","                input_seqs['attention_mask'],\n","                input_seqs['decoder_input_ids'],\n","                input_seqs['decoder_attention_mask'],\n","                training = True\n","            )\n","            logits = outputs.logits\n","            loss = self.loss_fn(input_labels, logits)\n","        gradients = tape.gradient(loss, self.model.trainable_weights)\n","        self.optimizer.apply_gradients(\n","            zip(gradients, self.model.trainable_weights)\n","        )\n","        self.loss_tracker.update_state(loss)\n","#         self.metric.update_state(y, predictions)\n","        return loss\n","        \n","    # Validation Step\n","    @tf.function  \n","    def val_step(self, inputs):\n","        input_seqs, input_labels = inputs\n","        outputs = self.model(                \n","                input_seqs['input_ids'],\n","                input_seqs['attention_mask'],\n","                input_seqs['decoder_input_ids'],\n","                input_seqs['decoder_attention_mask'],\n","                training = False\n","        )\n","        logits = outputs.logits\n","        loss = self.loss_fn(input_labels, logits)\n","        self.loss_tracker.update_state(loss)\n","#         self.metric.update_state(y,predictions)\n","        return loss"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T20:32:49.429490Z","iopub.status.busy":"2024-04-11T20:32:49.429240Z","iopub.status.idle":"2024-04-11T20:32:49.441976Z","shell.execute_reply":"2024-04-11T20:32:49.441257Z","shell.execute_reply.started":"2024-04-11T20:32:49.429453Z"},"trusted":true},"outputs":[],"source":["def batched_generate_summary(model, tokenizer, batched_input):\n","    input_seqs, input_labels = batched_input\n","    outputs = model.generate(\n","        input_ids=input_seqs['input_ids'], \n","        attention_mask=input_seqs['attention_mask']\n","    )\n","    output_strs = tokenizer.batch_decode(\n","        outputs, \n","        skip_special_tokens=True\n","    )\n","    output_gold = tokenizer.batch_decode(\n","        input_seqs['decoder_input_ids'], \n","        skip_special_tokens=True\n","    )\n","    input_strs = tokenizer.batch_decode(\n","        input_seqs['input_ids'], \n","        skip_special_tokens=True\n","    )\n","    return output_strs, output_gold, input_strs"]},{"cell_type":"markdown","metadata":{},"source":["# Bert2Bert"]},{"cell_type":"code","execution_count":21,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-04-11T20:33:17.993914Z","iopub.status.busy":"2024-04-11T20:33:17.993303Z","iopub.status.idle":"2024-04-11T20:33:31.254119Z","shell.execute_reply":"2024-04-11T20:33:31.253274Z","shell.execute_reply.started":"2024-04-11T20:33:17.993880Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"811fc9d2fab5400bbd58b4315d49e069","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4281b351215740f880dfbbd406160911","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c9e7db23c1b4eed9c03d79db9772270","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8bb17d180fd24e18ba418ea568047f9f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["reviews = df_reviews['Text'].values\n","summaries = df_reviews['Summary'].values\n","\n","training_config = TrainingConfig(nb_epoch=5)\n","tokenizer = BertTokenizerFast.from_pretrained(training_config.encoder_checkpoint)\n","\n","dataloader_args = {\n","    'tokenizer': tokenizer,\n","    'val_split': training_config.val_split,\n","    'encoder_max_len': training_config.encoder_max_len,\n","    'decoder_max_len': training_config.decoder_max_len\n","}\n","dataloader = DataLoader(reviews, summaries, **dataloader_args)\n","train_dataset, val_dataset = dataloader()\n","train_dataset = (train_dataset\n","                 .shuffle(int(dataloader.sample_size*(1-training_config.val_split)))\n","                 .batch(training_config.batch_size))\n","val_dataset = val_dataset.batch(training_config.batch_size)"]},{"cell_type":"code","execution_count":22,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-04-11T20:33:31.255934Z","iopub.status.busy":"2024-04-11T20:33:31.255669Z","iopub.status.idle":"2024-04-11T20:33:49.327992Z","shell.execute_reply":"2024-04-11T20:33:49.327439Z","shell.execute_reply.started":"2024-04-11T20:33:31.255904Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"391469ba66bf45f397456a4fe66b7ccd","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","All model checkpoint layers were used when initializing TFBertLMHeadModel.\n","\n","Some layers of TFBertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['tf_encoder_decoder_model_1/bert/encoder/layer_._6/crossattention/self/value/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._3/crossattention/self/value/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._5/crossattention/output/dense/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._8/crossattention/self/value/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._4/crossattention/output/dense/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._7/crossattention/self/value/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._5/crossattention/output/LayerNorm/gamma:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._1/crossattention/self/value/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._5/crossattention/output/dense/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._9/crossattention/self/key/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._9/crossattention/self/value/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._4/crossattention/output/dense/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._11/crossattention/self/key/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._10/crossattention/self/value/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._6/crossattention/self/query/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._10/crossattention/output/dense/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._9/crossattention/self/query/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._1/crossattention/self/key/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._6/crossattention/self/key/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._0/crossattention/self/value/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._0/crossattention/output/LayerNorm/beta:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._10/crossattention/self/value/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._3/crossattention/output/LayerNorm/gamma:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._8/crossattention/self/query/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._10/crossattention/output/dense/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._4/crossattention/self/value/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._4/crossattention/output/LayerNorm/beta:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._1/crossattention/output/dense/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._4/crossattention/self/key/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._6/crossattention/self/key/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._1/crossattention/output/LayerNorm/gamma:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._1/crossattention/self/value/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._6/crossattention/self/query/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._9/crossattention/output/dense/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._6/crossattention/output/LayerNorm/beta:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._11/crossattention/self/query/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._1/crossattention/self/key/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._11/crossattention/output/LayerNorm/beta:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._3/crossattention/self/key/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._5/crossattention/self/key/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._2/crossattention/self/key/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._3/crossattention/self/key/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._6/crossattention/output/dense/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._4/crossattention/self/value/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._7/crossattention/output/dense/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._11/crossattention/self/key/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._5/crossattention/self/query/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._11/crossattention/output/dense/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._0/crossattention/self/query/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._10/crossattention/output/LayerNorm/gamma:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._7/crossattention/self/key/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._4/crossattention/output/LayerNorm/gamma:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._9/crossattention/self/value/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._2/crossattention/self/value/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._9/crossattention/self/query/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._9/crossattention/output/dense/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._8/crossattention/output/dense/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._8/crossattention/output/dense/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._2/crossattention/output/LayerNorm/gamma:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._2/crossattention/self/key/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._2/crossattention/output/dense/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._6/crossattention/self/value/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._3/crossattention/self/query/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._1/crossattention/self/query/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._5/crossattention/self/key/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._8/crossattention/output/LayerNorm/gamma:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._5/crossattention/self/value/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._7/crossattention/output/LayerNorm/beta:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._2/crossattention/self/query/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._0/crossattention/output/dense/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._3/crossattention/output/dense/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._0/crossattention/self/key/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._6/crossattention/output/LayerNorm/gamma:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._9/crossattention/output/LayerNorm/gamma:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._10/crossattention/self/key/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._2/crossattention/output/LayerNorm/beta:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._11/crossattention/output/LayerNorm/gamma:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._4/crossattention/self/query/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._4/crossattention/self/key/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._1/crossattention/self/query/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._11/crossattention/self/value/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._8/crossattention/self/query/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._7/crossattention/output/LayerNorm/gamma:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._3/crossattention/output/dense/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._3/crossattention/output/LayerNorm/beta:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._10/crossattention/self/query/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._1/crossattention/output/dense/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._7/crossattention/output/dense/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._2/crossattention/self/query/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._8/crossattention/self/value/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._11/crossattention/self/value/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._0/crossattention/self/value/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._8/crossattention/self/key/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._4/crossattention/self/query/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._7/crossattention/self/query/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._10/crossattention/output/LayerNorm/beta:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._5/crossattention/output/LayerNorm/beta:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._6/crossattention/output/dense/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._9/crossattention/output/LayerNorm/beta:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._5/crossattention/self/query/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._7/crossattention/self/key/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._0/crossattention/output/dense/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._8/crossattention/output/LayerNorm/beta:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._3/crossattention/self/value/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._3/crossattention/self/query/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._0/crossattention/output/LayerNorm/gamma:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._2/crossattention/self/value/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._11/crossattention/self/query/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._7/crossattention/self/value/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._11/crossattention/output/dense/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._1/crossattention/output/LayerNorm/beta:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._9/crossattention/self/key/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._10/crossattention/self/key/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._7/crossattention/self/query/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._8/crossattention/self/key/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._5/crossattention/self/value/kernel:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._0/crossattention/self/query/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._10/crossattention/self/query/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._0/crossattention/self/key/bias:0', 'tf_encoder_decoder_model_1/bert/encoder/layer_._2/crossattention/output/dense/kernel:0']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["bert2bert = TFEncoderDecoderModel.from_encoder_decoder_pretrained(\n","    training_config.encoder_checkpoint, \n","    training_config.decoder_checkpoint,\n","    # whether to share the encoder weight\n","    tie_encoder_decoder=training_config.shared_weight\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T20:33:49.329678Z","iopub.status.busy":"2024-04-11T20:33:49.329409Z","iopub.status.idle":"2024-04-11T20:33:54.708502Z","shell.execute_reply":"2024-04-11T20:33:54.707670Z","shell.execute_reply.started":"2024-04-11T20:33:49.329640Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFEncoderDecoderModel.\n","\n","All the layers of TFEncoderDecoderModel were initialized from the model checkpoint at bert2bert.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFEncoderDecoderModel for predictions without further training.\n"]}],"source":["bert2bert.save_pretrained('bert2bert')\n","bert2bert = TFEncoderDecoderModel.from_pretrained('bert2bert')"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T20:33:54.710824Z","iopub.status.busy":"2024-04-11T20:33:54.710591Z","iopub.status.idle":"2024-04-11T20:33:54.716963Z","shell.execute_reply":"2024-04-11T20:33:54.716258Z","shell.execute_reply.started":"2024-04-11T20:33:54.710796Z"},"trusted":true},"outputs":[],"source":["# The special tokens for decoder should be aligned with the special tokens for encoder\n","# Since we are using Bert checkpoint for both decoder and decoder, \n","# the cls and sep tokens in the encoder could be used as the start and end token for the decoder\n","bert2bert.config.decoder_start_token_id = tokenizer.cls_token_id # 101\n","bert2bert.config.eos_token_id = tokenizer.sep_token_id # 102 \n","bert2bert.config.pad_token_id = tokenizer.pad_token_id # 0\n","bert2bert.config.vocab_size = bert2bert.config.encoder.vocab_size \n","\n","# These configurations are for the beam search in decoding process\n","bert2bert.config.max_length = 30\n","bert2bert.config.min_length = 3\n","bert2bert.config.no_repeat_ngram_size = 2\n","bert2bert.config.early_stopping = True\n","bert2bert.config.length_penalty = 2.0\n","bert2bert.config.num_beams = 4"]},{"cell_type":"code","execution_count":37,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-04-11T21:15:25.434227Z","iopub.status.busy":"2024-04-11T21:15:25.433924Z","iopub.status.idle":"2024-04-11T21:49:31.614629Z","shell.execute_reply":"2024-04-11T21:49:31.613960Z","shell.execute_reply.started":"2024-04-11T21:15:25.434176Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Epoch 1\n","\n","Training....\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"093d911754864375b7f2cb74cb11c3ed","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/999 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training loss for one batch at step 0: 1.6540000438690186\n","Training loss for one batch at step 200: 1.5099999904632568\n","Training loss for one batch at step 400: 1.5520000457763672\n","Training loss for one batch at step 600: 1.5759999752044678\n","Training loss for one batch at step 800: 1.5950000286102295\n","Validating....\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"634906a836574b9cb4dfc07e97ce7797","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/250 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation loss: 4.560999870300293\n","\n","Epoch 2\n","\n","Training....\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd22822d63ca4ac8adf6e8febff2ceb9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/999 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training loss for one batch at step 0: 1.3009999990463257\n","Training loss for one batch at step 200: 1.090999960899353\n","Training loss for one batch at step 400: 1.1230000257492065\n","Training loss for one batch at step 600: 1.1369999647140503\n","Training loss for one batch at step 800: 1.1510000228881836\n","Validating....\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4118d58f89de4737862ebb32f13c1d4c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/250 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation loss: 4.710000038146973\n","\n","Epoch 3\n","\n","Training....\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c6cdceb00624be1b817e36513e2ea94","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/999 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training loss for one batch at step 0: 0.8040000200271606\n","Training loss for one batch at step 200: 0.7990000247955322\n","Training loss for one batch at step 400: 0.8019999861717224\n","Training loss for one batch at step 600: 0.8209999799728394\n","Training loss for one batch at step 800: 0.8320000171661377\n","Validating....\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e7aa3f71975454981956a6298aea8f5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/250 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation loss: 4.800000190734863\n","\n","Epoch 4\n","\n","Training....\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c98dc32c3e147eb84aa614e6b80d291","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/999 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training loss for one batch at step 0: 0.6850000023841858\n","Training loss for one batch at step 200: 0.574999988079071\n","Training loss for one batch at step 400: 0.578000009059906\n","Training loss for one batch at step 600: 0.593999981880188\n","Training loss for one batch at step 800: 0.609000027179718\n","Validating....\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06b7e286525043f5ad0ed2e5644e2f3d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/250 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation loss: 4.9120001792907715\n","\n","Epoch 5\n","\n","Training....\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4cc9f3936f34198b29b68467b5d9215","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/999 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training loss for one batch at step 0: 0.4869999885559082\n","Training loss for one batch at step 200: 0.43299999833106995\n","Training loss for one batch at step 400: 0.44600000977516174\n","Training loss for one batch at step 600: 0.4519999921321869\n","Training loss for one batch at step 800: 0.4620000123977661\n","Validating....\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7cd9bca04bf41389903efbe7db095fe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/250 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation loss: 5.019999980926514\n"]}],"source":["rouge = datasets.load_metric('rouge')\n","tf.keras.backend.clear_session()\n","trainer = Trainer(model=bert2bert,\n","                  loss_fn=Seq2SeqLoss(training_config.pad_token_id),\n","                  optimizer=AdamWeightDecay(\n","                      learning_rate=training_config.learning_rate, \n","                      weight_decay_rate=0.005\n","                  ),\n","                  metric=None)\n","\n","# Training Loop\n","for epoch in range(training_config.nb_epoch):\n","    print(f'\\nEpoch {epoch+1}\\n')\n","    print('Training....')\n","    for step,batched_input in enumerate(tqdm(train_dataset)):\n","        loss = trainer.train_step(batched_input)\n","        till_now_loss = trainer.loss_tracker.result()\n","        if step%200 == 0:\n","            print(f'Training loss for one batch at step {step}: {round(till_now_loss,3)}') \n","    trainer.loss_tracker.reset_states()\n","    \n","    print('Validating....')\n","    val_measures = {'rouge precision':0, 'rouge recall':0, 'rouge f1': 0}\n","    for step, batched_input in enumerate(tqdm(val_dataset)):\n","        val_loss = trainer.val_step(batched_input)\n","#         pred_str, gold_str = generate_summary(bert2bert, \n","#                                               tokenizer, \n","#                                               batched_input)\n","#         rouge_output = rouge.compute(predictions=pred_str,\n","#                                      references=gold_str,\n","#                                      rouge_types=['rouge2'])['rouge2'].mid\n","#         val_measures['rouge precision'] += rouge_output.precision / len(val_dataset)\n","#         val_measures['rouge recall'] += rouge_output.recall / len(val_dataset)\n","#         val_measures['rouge f1'] += rouge_output.fmeasure / len(val_dataset)\n","    till_now_val_loss = trainer.loss_tracker.result()\n","    print(f'Validation loss: {round(till_now_val_loss,3)}')\n","    bert2bert.save_pretrained(\n","        f'/kaggle/working/bert2bert-Checkpoint-epoch{epoch+1}-loss{round(till_now_val_loss,3)}'\n","    )\n","#     for name, value in val_measures.items():\n","#         print(f'Validation {name}: {value}')\n","    trainer.loss_tracker.reset_states()"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T21:50:04.388616Z","iopub.status.busy":"2024-04-11T21:50:04.387843Z","iopub.status.idle":"2024-04-11T21:50:08.065891Z","shell.execute_reply":"2024-04-11T21:50:08.065149Z","shell.execute_reply.started":"2024-04-11T21:50:04.388578Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFEncoderDecoderModel.\n","\n","All the layers of TFEncoderDecoderModel were initialized from the model checkpoint at /kaggle/working/bert2bert-Checkpoint-epoch3-loss4.329999923706055.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFEncoderDecoderModel for predictions without further training.\n"]}],"source":["# Load the best model checkpoint\n","trained_bert2bert = TFEncoderDecoderModel.from_pretrained(\n","    'bert2bert-Checkpoint-epoch3-loss4.329999923706055'\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Let's see what is our generated output look like!"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T21:50:11.867920Z","iopub.status.busy":"2024-04-11T21:50:11.867668Z","iopub.status.idle":"2024-04-11T21:50:28.252015Z","shell.execute_reply":"2024-04-11T21:50:28.251283Z","shell.execute_reply.started":"2024-04-11T21:50:11.867892Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a27120dd7b94bbb9e37f0fc71de2782","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/250 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Rouge report: \n","Score(precision=0.15556908369408368, recall=0.1751488095238095, fmeasure=0.15963069438301636)\n","====================================================================================================\n","Review: a foreign business executive participating in the ongoing # # # # taiwan business alliance conference said monday he hopes the two sides of the taiwan strait can establish direct transportation links as soon as possible.\n","Summary: foreign executives advocate direct cross - strait transport links\n","Generated: foreign trade council says taiwan will cooperate with taiwan\n","====================================================================================================\n","Review: two companies listed on the dar es salaam stock exchange - lrb - dse - rrb - have announced their respective plans of dividend payment to be made next month.\n","Summary: tanzanian listed companies announce dividend payment plans\n","Generated: sala to issue new subscribe - subsem rates\n","====================================================================================================\n","Review: defense secretary donald h. rumsfeld spent tuesday in a whirlwind trip around iraq that included meetings with american troops outside the capital, meetings with government officials in baghdad, and a final stop here, at a kurdish stronghold beneath snow - capped mountains where anti - saddam hussein forces plotted for years against the iraqi dictator - - and against other kurds.\n","Summary: rumsfeld laces talks to iraqis with optimism and warnings\n","Generated: rumsfeld takes on iraq war\n","====================================================================================================\n","Review: world no. # jean - michel saive of belgium downed croatian zoran primorac # # - # #, # # - # #, # # - # #, # # - # # to move into the final of the world cup table tennis tournament here saturday.\n","Summary: unk gatien reach final of world cup championships\n","Generated: top top world cup champions champions to reach semifinals in semifinals\n","====================================================================================================\n","Review: european stock markets steadied in early trading on monday after a rally last week, with mining stocks providing support in london.\n","Summary: european stocks steady in early deals\n","Generated: european markets rally mixed after wall street gains\n","====================================================================================================\n","Review: the hong kong branch of bank of china has given a # # - million - dollar loan to hong kong's shui on group to finance an urban redevelopment project in shanghai, the company said thursday.\n","Summary: bank of china bankrolls shanghai property project\n","Generated: bank of hong kong lends $ # #. # million to hk\n","====================================================================================================\n","Review: thierry henry gave france a # - # level with portugal in euro # # # # semifinal at the king baudouin stadium on wednesday.\n","Summary: france levels # - # with portugal\n","Generated: france to win world cup cup final\n","====================================================================================================\n","Review: bodies of all the eight trapped miners have been retrieved after a gas outburst in a coal mine in northwest china's shaanxi province, rescuers said on sunday.\n","Summary: death toll rises to eight in china colliery gas outburst\n","Generated: four miners recovered from china mine explosion\n"]}],"source":["# val0 = list(val_dataset.as_numpy_iterator())[0]\n","for step, batched_input in enumerate(tqdm(val_dataset)):\n","    pred_str, gold_str, input_strs = batched_generate_summary(\n","        trained_bert2bert, \n","        tokenizer, \n","        batched_input\n","    )\n","    rouge_output = rouge.compute(\n","        predictions=pred_str,\n","        references=gold_str,\n","        rouge_types=[\"rouge1\"]\n","    )\n","    print('Rouge report: ')\n","    print(rouge_output['rouge1'].mid)\n","    for p_str,g_str,in_str in zip(pred_str, gold_str, input_strs):\n","        print('='*100)\n","        print('Review: ' + in_str)\n","        print('Summary: ' + g_str)\n","        print('Generated: ' + p_str)\n","    \n","    break"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T21:58:55.163707Z","iopub.status.busy":"2024-04-11T21:58:55.162868Z","iopub.status.idle":"2024-04-11T22:01:45.012331Z","shell.execute_reply":"2024-04-11T22:01:45.011530Z","shell.execute_reply.started":"2024-04-11T21:58:55.163657Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cae0742ea55d40148fbc60c8b6d9c3fc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'rouge1': AggregateScore(low=Score(precision=0.3303154761904761, recall=0.3006857548701298, fmeasure=0.31052319277686524), mid=Score(precision=0.3735716089466089, recall=0.34221338383838384, fmeasure=0.3499700360011505), high=Score(precision=0.4189004329004327, recall=0.38829684343434345, fmeasure=0.391930746404438))}\n"]}],"source":["df_reviews_test = df_reviews.copy()\n","df_reviews_test = df_reviews_test.iloc[1000:1100, :]\n","test_reviews = df_reviews_test['Text'].values\n","test_sums = df_reviews_test['Summary'].values\n","\n","test_dataloader = DataLoader(test_reviews, test_sums, **dataloader_args)\n","test_dataset = test_dataloader.list_to_tensor_dataset(test_reviews, test_sums)\n","test_dataset = test_dataset.batch(training_config.batch_size)\n","pred_strs = []\n","gold_strs = []\n","\n","for batched_input in tqdm(test_dataset):\n","    pred_str, gold_str, _ = batched_generate_summary(\n","        trained_bert2bert, \n","        tokenizer, \n","        batched_input\n","    )\n","    pred_strs.extend(pred_str)\n","    gold_strs.extend(gold_str)\n","    \n","rouge_output = rouge.compute(\n","    predictions=pred_strs,\n","    references=gold_strs,\n","    rouge_types=[\"rouge1\"]\n",")\n","pprint(rouge_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:14:42.838952Z","iopub.status.busy":"2024-04-11T22:14:42.838196Z","iopub.status.idle":"2024-04-11T22:14:46.311587Z","shell.execute_reply":"2024-04-11T22:14:46.310718Z","shell.execute_reply.started":"2024-04-11T22:14:42.838916Z"},"trusted":true},"outputs":[],"source":["# Save the trained_bert2bert model\n","trained_bert2bert.save_pretrained('trained_bert2bert.h5')\n","trained_bert2bert.save_pretrained('trained_bert2bert.json')\n","# Save the tokenizer\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:28:31.186926Z","iopub.status.busy":"2024-04-11T22:28:31.186156Z","iopub.status.idle":"2024-04-11T22:28:31.239882Z","shell.execute_reply":"2024-04-11T22:28:31.239120Z","shell.execute_reply.started":"2024-04-11T22:28:31.186878Z"},"trusted":true},"outputs":[],"source":["tokenizer.save_pretrained('tokenizer/')"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:21:15.698645Z","iopub.status.busy":"2024-04-11T22:21:15.698311Z","iopub.status.idle":"2024-04-11T22:23:03.158922Z","shell.execute_reply":"2024-04-11T22:23:03.158108Z","shell.execute_reply.started":"2024-04-11T22:21:15.698609Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","  adding: kaggle/working/trained_bert2bert.h5/ (stored 0%)\n","  adding: kaggle/working/trained_bert2bert.h5/tf_model.h5 (deflated 8%)\n","  adding: kaggle/working/trained_bert2bert.h5/config.json (deflated 80%)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","  adding: kaggle/working/trained_bert2bert.json/ (stored 0%)\n","  adding: kaggle/working/trained_bert2bert.json/tf_model.h5 (deflated 8%)\n","  adding: kaggle/working/trained_bert2bert.json/config.json (deflated 80%)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","  adding: kaggle/working/tokenizer.json/ (stored 0%)\n","  adding: kaggle/working/tokenizer.json/vocab.txt (deflated 53%)\n","  adding: kaggle/working/tokenizer.json/tokenizer_config.json (deflated 39%)\n","  adding: kaggle/working/tokenizer.json/special_tokens_map.json (deflated 40%)\n","  adding: kaggle/working/tokenizer.json/tokenizer.json (deflated 59%)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","  adding: kaggle/working/tokenizer.h5/ (stored 0%)\n","  adding: kaggle/working/tokenizer.h5/vocab.txt (deflated 53%)\n","  adding: kaggle/working/tokenizer.h5/tokenizer_config.json (deflated 39%)\n","  adding: kaggle/working/tokenizer.h5/special_tokens_map.json (deflated 40%)\n","  adding: kaggle/working/tokenizer.h5/tokenizer.json (deflated 59%)\n"]}],"source":["!zip -r trained_bert2bert_h5.zip /trained_bert2bert.h5\n","!zip -r trained_bert2bert_json.zip /trained_bert2bert.json\n","\n","\n"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:29:26.275849Z","iopub.status.busy":"2024-04-11T22:29:26.275547Z","iopub.status.idle":"2024-04-11T22:29:27.372099Z","shell.execute_reply":"2024-04-11T22:29:27.371275Z","shell.execute_reply.started":"2024-04-11T22:29:26.275815Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","  adding: kaggle/working/tokenizer/ (stored 0%)\n","  adding: kaggle/working/tokenizer/vocab.txt (deflated 53%)\n","  adding: kaggle/working/tokenizer/tokenizer_config.json (deflated 39%)\n","  adding: kaggle/working/tokenizer/special_tokens_map.json (deflated 40%)\n","  adding: kaggle/working/tokenizer/tokenizer.json (deflated 59%)\n"]}],"source":["!zip -r tokenizer.zip /working/tokenizer/"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:23:26.698571Z","iopub.status.busy":"2024-04-11T22:23:26.697796Z","iopub.status.idle":"2024-04-11T22:23:26.704508Z","shell.execute_reply":"2024-04-11T22:23:26.703661Z","shell.execute_reply.started":"2024-04-11T22:23:26.698530Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='trained_bert2bert_h5.zip' target='_blank'>trained_bert2bert_h5.zip</a><br>"],"text/plain":["/kaggle/working/trained_bert2bert_h5.zip"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import FileLink \n","FileLink(r'trained_bert2bert_h5.zip')"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:23:29.293826Z","iopub.status.busy":"2024-04-11T22:23:29.293064Z","iopub.status.idle":"2024-04-11T22:23:29.299307Z","shell.execute_reply":"2024-04-11T22:23:29.298557Z","shell.execute_reply.started":"2024-04-11T22:23:29.293792Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='trained_bert2bert_json.zip' target='_blank'>trained_bert2bert_json.zip</a><br>"],"text/plain":["/kaggle/working/trained_bert2bert_json.zip"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import FileLink \n","FileLink(r'trained_bert2bert_json.zip')"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:29:42.006644Z","iopub.status.busy":"2024-04-11T22:29:42.005808Z","iopub.status.idle":"2024-04-11T22:29:42.012697Z","shell.execute_reply":"2024-04-11T22:29:42.011963Z","shell.execute_reply.started":"2024-04-11T22:29:42.006601Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='tokenizer.zip' target='_blank'>tokenizer.zip</a><br>"],"text/plain":["/kaggle/working/tokenizer.zip"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import FileLink \n","FileLink(r'tokenizer.zip')"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:23:33.028026Z","iopub.status.busy":"2024-04-11T22:23:33.027489Z","iopub.status.idle":"2024-04-11T22:23:33.033749Z","shell.execute_reply":"2024-04-11T22:23:33.032934Z","shell.execute_reply.started":"2024-04-11T22:23:33.027984Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='tokenizer_h5.zip' target='_blank'>tokenizer_h5.zip</a><br>"],"text/plain":["/kaggle/working/tokenizer_h5.zip"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import FileLink \n","FileLink(r'tokenizer_h5.zip')"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:30:07.186360Z","iopub.status.busy":"2024-04-11T22:30:07.185644Z","iopub.status.idle":"2024-04-11T22:30:11.262185Z","shell.execute_reply":"2024-04-11T22:30:11.261573Z","shell.execute_reply.started":"2024-04-11T22:30:07.186310Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFEncoderDecoderModel.\n","\n","All the layers of TFEncoderDecoderModel were initialized from the model checkpoint at /kaggle/working/trained_bert2bert.h5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFEncoderDecoderModel for predictions without further training.\n"]}],"source":["from transformers import TFEncoderDecoderModel, BertTokenizerFast\n","\n","# Load the trained_bert2bert model\n","loaded_model = TFEncoderDecoderModel.from_pretrained(\"trained_bert2bert.h5\")\n","\n","# Load the tokenizer\n","loaded_tokenizer = BertTokenizerFast.from_pretrained(\"tokenizer/\")\n"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:32:22.315568Z","iopub.status.busy":"2024-04-11T22:32:22.314734Z","iopub.status.idle":"2024-04-11T22:35:12.840024Z","shell.execute_reply":"2024-04-11T22:35:12.839229Z","shell.execute_reply.started":"2024-04-11T22:32:22.315529Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a57f3acce914c9082cf729b4a96a701","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'rouge1': AggregateScore(low=Score(precision=0.3303154761904761, recall=0.3006857548701298, fmeasure=0.31052319277686524), mid=Score(precision=0.3735716089466089, recall=0.34221338383838384, fmeasure=0.3499700360011505), high=Score(precision=0.4189004329004327, recall=0.38829684343434345, fmeasure=0.391930746404438))}\n"]}],"source":["df_reviews_test = df_reviews.copy()\n","df_reviews_test = df_reviews_test.iloc[1000:1100, :]\n","test_reviews = df_reviews_test['Text'].values\n","test_sums = df_reviews_test['Summary'].values\n","\n","test_dataloader = DataLoader(test_reviews, test_sums, **dataloader_args)\n","test_dataset = test_dataloader.list_to_tensor_dataset(test_reviews, test_sums)\n","test_dataset = test_dataset.batch(training_config.batch_size)\n","pred_strs = []\n","gold_strs = []\n","\n","for batched_input in tqdm(test_dataset):\n","    pred_str, gold_str, _ = batched_generate_summary(\n","        loaded_model, \n","        loaded_tokenizer, \n","        batched_input\n","    )\n","    pred_strs.extend(pred_str)\n","    gold_strs.extend(gold_str)\n","    \n","rouge_output = rouge.compute(\n","    predictions=pred_strs,\n","    references=gold_strs,\n","    rouge_types=[\"rouge1\"]\n",")\n","pprint(rouge_output)"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:35:29.391168Z","iopub.status.busy":"2024-04-11T22:35:29.390848Z","iopub.status.idle":"2024-04-11T22:35:45.403355Z","shell.execute_reply":"2024-04-11T22:35:45.402551Z","shell.execute_reply.started":"2024-04-11T22:35:29.391133Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd4c706697b64825975a0ef7de45c614","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/250 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Rouge report: \n","Score(precision=0.15556908369408368, recall=0.1751488095238095, fmeasure=0.15963069438301636)\n","====================================================================================================\n","Review: a foreign business executive participating in the ongoing # # # # taiwan business alliance conference said monday he hopes the two sides of the taiwan strait can establish direct transportation links as soon as possible.\n","Summary: foreign executives advocate direct cross - strait transport links\n","Generated: foreign trade council says taiwan will cooperate with taiwan\n","====================================================================================================\n","Review: two companies listed on the dar es salaam stock exchange - lrb - dse - rrb - have announced their respective plans of dividend payment to be made next month.\n","Summary: tanzanian listed companies announce dividend payment plans\n","Generated: sala to issue new subscribe - subsem rates\n","====================================================================================================\n","Review: defense secretary donald h. rumsfeld spent tuesday in a whirlwind trip around iraq that included meetings with american troops outside the capital, meetings with government officials in baghdad, and a final stop here, at a kurdish stronghold beneath snow - capped mountains where anti - saddam hussein forces plotted for years against the iraqi dictator - - and against other kurds.\n","Summary: rumsfeld laces talks to iraqis with optimism and warnings\n","Generated: rumsfeld takes on iraq war\n","====================================================================================================\n","Review: world no. # jean - michel saive of belgium downed croatian zoran primorac # # - # #, # # - # #, # # - # #, # # - # # to move into the final of the world cup table tennis tournament here saturday.\n","Summary: unk gatien reach final of world cup championships\n","Generated: top top world cup champions champions to reach semifinals in semifinals\n","====================================================================================================\n","Review: european stock markets steadied in early trading on monday after a rally last week, with mining stocks providing support in london.\n","Summary: european stocks steady in early deals\n","Generated: european markets rally mixed after wall street gains\n","====================================================================================================\n","Review: the hong kong branch of bank of china has given a # # - million - dollar loan to hong kong's shui on group to finance an urban redevelopment project in shanghai, the company said thursday.\n","Summary: bank of china bankrolls shanghai property project\n","Generated: bank of hong kong lends $ # #. # million to hk\n","====================================================================================================\n","Review: thierry henry gave france a # - # level with portugal in euro # # # # semifinal at the king baudouin stadium on wednesday.\n","Summary: france levels # - # with portugal\n","Generated: france to win world cup cup final\n","====================================================================================================\n","Review: bodies of all the eight trapped miners have been retrieved after a gas outburst in a coal mine in northwest china's shaanxi province, rescuers said on sunday.\n","Summary: death toll rises to eight in china colliery gas outburst\n","Generated: four miners recovered from china mine explosion\n"]}],"source":["# val0 = list(val_dataset.as_numpy_iterator())[0]\n","for step, batched_input in enumerate(tqdm(val_dataset)):\n","    pred_str, gold_str, input_strs = batched_generate_summary(\n","        loaded_model, \n","        loaded_tokenizer, \n","        batched_input\n","    )\n","    rouge_output = rouge.compute(\n","        predictions=pred_str,\n","        references=gold_str,\n","        rouge_types=[\"rouge1\"]\n","    )\n","    print('Rouge report: ')\n","    print(rouge_output['rouge1'].mid)\n","    for p_str,g_str,in_str in zip(pred_str, gold_str, input_strs):\n","        print('='*100)\n","        print('Review: ' + in_str)\n","        print('Summary: ' + g_str)\n","        print('Generated: ' + p_str)\n","    \n","    break"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":18,"sourceId":2157,"sourceType":"datasetVersion"},{"datasetId":1866508,"sourceId":3048139,"sourceType":"datasetVersion"},{"datasetId":4778472,"sourceId":8093493,"sourceType":"datasetVersion"}],"dockerImageVersionId":30153,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
